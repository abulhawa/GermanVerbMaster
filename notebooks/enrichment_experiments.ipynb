{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enrichment API Exploration\n",
        "\n",
        "This notebook mirrors the admin enrichment tooling so you can experiment with the same API endpoints and parsing logic outside the web UI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Requirements\n",
        "\n",
        "Install the following packages in the environment where you plan to run the notebook:\n",
        "\n",
        "- Python 3.10 or newer\n",
        "- [`requests`](https://pypi.org/project/requests/)\n",
        "- [`python-dotenv`](https://pypi.org/project/python-dotenv/) *(optional, for loading a `.env` file with API tokens)*\n",
        "- [`ipykernel`](https://pypi.org/project/ipykernel/) *(if you need to register the environment as a Jupyter kernel)*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set `GVM_API_BASE_URL` to point at the German Verb Master backend (e.g. `http://localhost:3000`).\n",
        "You can also provide an optional `GVM_ADMIN_TOKEN` if the enrichment endpoints require the admin header.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "import os\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, TypedDict, Literal\n",
        "\n",
        "import requests\n",
        "\n",
        "API_BASE_URL = os.getenv(\"GVM_API_BASE_URL\", \"http://localhost:3000\").rstrip('/')\n",
        "ADMIN_TOKEN = os.getenv(\"GVM_ADMIN_TOKEN\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class RunEnrichmentPayload(TypedDict, total=False):\n",
        "    limit: int\n",
        "    mode: Literal['non-canonical', 'canonical', 'all']\n",
        "    onlyIncomplete: bool\n",
        "    enableAi: bool\n",
        "    allowOverwrite: bool\n",
        "    collectSynonyms: bool\n",
        "    collectExamples: bool\n",
        "    collectTranslations: bool\n",
        "    collectWiktionary: bool\n",
        "\n",
        "class WordEnrichmentOptions(TypedDict, total=False):\n",
        "    enableAi: bool\n",
        "    allowOverwrite: bool\n",
        "    collectSynonyms: bool\n",
        "    collectExamples: bool\n",
        "    collectTranslations: bool\n",
        "    collectWiktionary: bool\n",
        "\n",
        "class EnrichmentPatch(TypedDict, total=False):\n",
        "    english: Optional[str]\n",
        "    exampleDe: Optional[str]\n",
        "    exampleEn: Optional[str]\n",
        "    sourcesCsv: Optional[str]\n",
        "    complete: Optional[bool]\n",
        "    praeteritum: Optional[str]\n",
        "    partizipIi: Optional[str]\n",
        "    perfekt: Optional[str]\n",
        "    aux: Optional[Literal['haben', 'sein']]\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentTranslationCandidate:\n",
        "    value: str\n",
        "    source: str\n",
        "    confidence: Optional[float] = None\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentExampleCandidate:\n",
        "    source: str\n",
        "    exampleDe: Optional[str] = None\n",
        "    exampleEn: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentVerbFormSuggestion:\n",
        "    source: str\n",
        "    praeteritum: Optional[str] = None\n",
        "    partizipIi: Optional[str] = None\n",
        "    perfekt: Optional[str] = None\n",
        "    aux: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentProviderDiagnostic:\n",
        "    id: str\n",
        "    label: str\n",
        "    status: Literal['success', 'error', 'skipped']\n",
        "    error: Optional[str] = None\n",
        "    payload: Optional[Any] = None\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentFieldUpdate:\n",
        "    field: str\n",
        "    previous: Any\n",
        "    next: Any\n",
        "    source: Optional[str] = None\n",
        "\n",
        "@dataclass\n",
        "class WordEnrichmentSuggestions:\n",
        "    translations: List[EnrichmentTranslationCandidate] = field(default_factory=list)\n",
        "    examples: List[EnrichmentExampleCandidate] = field(default_factory=list)\n",
        "    synonyms: List[str] = field(default_factory=list)\n",
        "    englishHints: List[str] = field(default_factory=list)\n",
        "    wiktionarySummary: Optional[str] = None\n",
        "    verbForms: List[EnrichmentVerbFormSuggestion] = field(default_factory=list)\n",
        "    providerDiagnostics: List[EnrichmentProviderDiagnostic] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class EnrichmentWordSummary:\n",
        "    id: int\n",
        "    lemma: str\n",
        "    pos: str\n",
        "    missingFields: List[str] = field(default_factory=list)\n",
        "    synonyms: List[str] = field(default_factory=list)\n",
        "    sources: List[str] = field(default_factory=list)\n",
        "    applied: bool = False\n",
        "    aiUsed: bool = False\n",
        "    translation: Optional[EnrichmentTranslationCandidate] = None\n",
        "    englishHints: Optional[List[str]] = None\n",
        "    wiktionarySummary: Optional[str] = None\n",
        "    example: Optional[EnrichmentExampleCandidate] = None\n",
        "    verbForms: Optional[EnrichmentVerbFormSuggestion] = None\n",
        "    updates: Optional[List[EnrichmentFieldUpdate]] = None\n",
        "    errors: Optional[List[str]] = None\n",
        "\n",
        "@dataclass\n",
        "class WordEnrichmentPreview:\n",
        "    summary: EnrichmentWordSummary\n",
        "    patch: EnrichmentPatch\n",
        "    hasUpdates: bool\n",
        "    suggestions: WordEnrichmentSuggestions\n",
        "\n",
        "@dataclass\n",
        "class BulkEnrichmentResponse:\n",
        "    scanned: int\n",
        "    updated: int\n",
        "    words: List[EnrichmentWordSummary] = field(default_factory=list)\n",
        "\n",
        "@dataclass\n",
        "class ApplyEnrichmentResponse:\n",
        "    word: Any\n",
        "    appliedFields: List[str] = field(default_factory=list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _map_translation_candidate(data: Dict[str, Any]) -> EnrichmentTranslationCandidate:\n",
        "    return EnrichmentTranslationCandidate(\n",
        "        value=data.get('value', ''),\n",
        "        source=data.get('source', ''),\n",
        "        confidence=data.get('confidence'),\n",
        "    )\n",
        "\n",
        "def _map_example_candidate(data: Dict[str, Any]) -> EnrichmentExampleCandidate:\n",
        "    return EnrichmentExampleCandidate(\n",
        "        source=data.get('source', ''),\n",
        "        exampleDe=data.get('exampleDe'),\n",
        "        exampleEn=data.get('exampleEn'),\n",
        "    )\n",
        "\n",
        "def _map_verb_form_suggestion(data: Dict[str, Any]) -> EnrichmentVerbFormSuggestion:\n",
        "    return EnrichmentVerbFormSuggestion(\n",
        "        source=data.get('source', ''),\n",
        "        praeteritum=data.get('praeteritum'),\n",
        "        partizipIi=data.get('partizipIi'),\n",
        "        perfekt=data.get('perfekt'),\n",
        "        aux=data.get('aux'),\n",
        "    )\n",
        "\n",
        "def _map_provider_diagnostic(data: Dict[str, Any]) -> EnrichmentProviderDiagnostic:\n",
        "    return EnrichmentProviderDiagnostic(\n",
        "        id=data.get('id', ''),\n",
        "        label=data.get('label', ''),\n",
        "        status=data.get('status', 'skipped'),\n",
        "        error=data.get('error'),\n",
        "        payload=data.get('payload'),\n",
        "    )\n",
        "\n",
        "def _map_field_update(data: Dict[str, Any]) -> EnrichmentFieldUpdate:\n",
        "    return EnrichmentFieldUpdate(\n",
        "        field=data.get('field', ''),\n",
        "        previous=data.get('previous'),\n",
        "        next=data.get('next'),\n",
        "        source=data.get('source'),\n",
        "    )\n",
        "\n",
        "def _map_word_summary(data: Dict[str, Any]) -> EnrichmentWordSummary:\n",
        "    translation = data.get('translation')\n",
        "    example = data.get('example')\n",
        "    verb_forms = data.get('verbForms')\n",
        "    return EnrichmentWordSummary(\n",
        "        id=data.get('id'),\n",
        "        lemma=data.get('lemma', ''),\n",
        "        pos=data.get('pos', ''),\n",
        "        missingFields=list(data.get('missingFields', [])),\n",
        "        synonyms=list(data.get('synonyms', [])),\n",
        "        sources=list(data.get('sources', [])),\n",
        "        applied=bool(data.get('applied', False)),\n",
        "        aiUsed=bool(data.get('aiUsed', False)),\n",
        "        translation=_map_translation_candidate(translation) if translation else None,\n",
        "        englishHints=list(data.get('englishHints') or []) or None,\n",
        "        wiktionarySummary=data.get('wiktionarySummary'),\n",
        "        example=_map_example_candidate(example) if example else None,\n",
        "        verbForms=_map_verb_form_suggestion(verb_forms) if verb_forms else None,\n",
        "        updates=[_map_field_update(item) for item in data.get('updates', [])] or None,\n",
        "        errors=list(data.get('errors', [])) or None,\n",
        "    )\n",
        "\n",
        "def _map_suggestions(data: Dict[str, Any]) -> WordEnrichmentSuggestions:\n",
        "    return WordEnrichmentSuggestions(\n",
        "        translations=[_map_translation_candidate(item) for item in data.get('translations', [])],\n",
        "        examples=[_map_example_candidate(item) for item in data.get('examples', [])],\n",
        "        synonyms=list(data.get('synonyms', [])),\n",
        "        englishHints=list(data.get('englishHints', [])),\n",
        "        wiktionarySummary=data.get('wiktionarySummary'),\n",
        "        verbForms=[_map_verb_form_suggestion(item) for item in data.get('verbForms', [])],\n",
        "        providerDiagnostics=[_map_provider_diagnostic(item) for item in data.get('providerDiagnostics', [])],\n",
        "    )\n",
        "\n",
        "def parse_word_preview(data: Dict[str, Any]) -> WordEnrichmentPreview:\n",
        "    return WordEnrichmentPreview(\n",
        "        summary=_map_word_summary(data.get('summary', {})),\n",
        "        patch=data.get('patch', {}),\n",
        "        hasUpdates=bool(data.get('hasUpdates', False)),\n",
        "        suggestions=_map_suggestions(data.get('suggestions', {})),\n",
        "    )\n",
        "\n",
        "def parse_bulk_response(data: Dict[str, Any]) -> BulkEnrichmentResponse:\n",
        "    return BulkEnrichmentResponse(\n",
        "        scanned=int(data.get('scanned', 0)),\n",
        "        updated=int(data.get('updated', 0)),\n",
        "        words=[_map_word_summary(item) for item in data.get('words', [])],\n",
        "    )\n",
        "\n",
        "def parse_apply_response(data: Dict[str, Any]) -> ApplyEnrichmentResponse:\n",
        "    return ApplyEnrichmentResponse(\n",
        "        word=data.get('word'),\n",
        "        appliedFields=list(data.get('appliedFields', [])),\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _request(path: str, *, method: str = 'GET', payload: Optional[Dict[str, Any]] = None, admin_token: Optional[str] = None) -> Dict[str, Any]:\n",
        "    url = f\"{API_BASE_URL}{path}\" if path.startswith('/') else f\"{API_BASE_URL}/{path}\"\n",
        "    headers = {'Content-Type': 'application/json'}\n",
        "    token = admin_token or ADMIN_TOKEN\n",
        "    if token:\n",
        "        headers['x-admin-token'] = token.strip()\n",
        "\n",
        "    response = requests.request(method, url, headers=headers, json=payload)\n",
        "\n",
        "    if response.status_code >= 400:\n",
        "        message = response.text or f\"Request failed with status {response.status_code}\"\n",
        "        raise RuntimeError(message)\n",
        "\n",
        "    try:\n",
        "        return response.json()\n",
        "    except json.JSONDecodeError as exc:\n",
        "        raise RuntimeError('Response did not contain valid JSON') from exc\n",
        "\n",
        "def run_bulk_enrichment(payload: RunEnrichmentPayload, *, admin_token: Optional[str] = None) -> BulkEnrichmentResponse:\n",
        "    data = _request('/api/enrichment/run', method='POST', payload=payload, admin_token=admin_token)\n",
        "    return parse_bulk_response(data)\n",
        "\n",
        "def preview_word_enrichment(word_id: int, options: WordEnrichmentOptions, *, admin_token: Optional[str] = None) -> WordEnrichmentPreview:\n",
        "    data = _request(f'/api/enrichment/words/{word_id}/preview', method='POST', payload=options, admin_token=admin_token)\n",
        "    return parse_word_preview(data)\n",
        "\n",
        "def apply_word_enrichment(word_id: int, patch: EnrichmentPatch, *, admin_token: Optional[str] = None) -> ApplyEnrichmentResponse:\n",
        "    data = _request(\n",
        "        f'/api/enrichment/words/{word_id}/apply',\n",
        "        method='POST',\n",
        "        payload={'patch': patch},\n",
        "        admin_token=admin_token,\n",
        "    )\n",
        "    return parse_apply_response(data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Usage Examples\n",
        "\n",
        "Uncomment and adapt the snippets below to run live calls once the backend is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: run a non-canonical enrichment scan\n",
        "# response = run_bulk_enrichment({\n",
        "#     'mode': 'non-canonical',\n",
        "#     'limit': 5,\n",
        "#     'collectTranslations': True,\n",
        "#     'collectWiktionary': True,\n",
        "# })\n",
        "# response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: preview enrichment for a specific word\n",
        "# preview = preview_word_enrichment(\n",
        "#     word_id=123,\n",
        "#     options={\n",
        "#         'collectTranslations': True,\n",
        "#         'collectExamples': True,\n",
        "#         'collectWiktionary': True,\n",
        "#     },\n",
        "# )\n",
        "# preview\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: apply a curated patch after reviewing suggestions\n",
        "# apply_word_enrichment(\n",
        "#     word_id=123,\n",
        "#     patch={\n",
        "#         'english': 'to do',\n",
        "#         'praeteritum': 'tat',\n",
        "#         'partizipIi': 'getan',\n",
        "#         'aux': 'haben',\n",
        "#     },\n",
        "# )\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}